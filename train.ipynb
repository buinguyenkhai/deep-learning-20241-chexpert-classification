{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-12T07:09:18.260556Z",
     "iopub.status.busy": "2024-12-12T07:09:18.259867Z",
     "iopub.status.idle": "2024-12-12T07:09:18.265985Z",
     "shell.execute_reply": "2024-12-12T07:09:18.265128Z",
     "shell.execute_reply.started": "2024-12-12T07:09:18.260518Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, DataLoader, BatchSampler, WeightedRandomSampler\n",
    "\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T07:09:18.268568Z",
     "iopub.status.busy": "2024-12-12T07:09:18.267945Z",
     "iopub.status.idle": "2024-12-12T07:09:18.288582Z",
     "shell.execute_reply": "2024-12-12T07:09:18.287857Z",
     "shell.execute_reply.started": "2024-12-12T07:09:18.268529Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CheXpertDataset(Dataset):\n",
    "    def __init__(self, data, root_dir, mode='train', transforms=None):\n",
    "        self.data = data.to_numpy()\n",
    "        self.labels = torch.tensor(data.values.astype(np.float32))\n",
    "        self.root_dir = root_dir\n",
    "        self.img_paths = [os.path.join(root_dir, img_path) for img_path in data.index]\n",
    "        self.transform = transforms.get(mode)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image=np.array(image))['image']\n",
    "\n",
    "        return (image, label)\n",
    "    \n",
    "def get_weighted_batch_sampler(data, batch_size):\n",
    "    weights = 1/data.sum()\n",
    "    weighted_sampler = WeightedRandomSampler(weights, len(data), replacement=True)\n",
    "    batch_sampler = BatchSampler(weighted_sampler, batch_size, drop_last=False)\n",
    "    return batch_sampler\n",
    "\n",
    "transform = {\n",
    "    'train': A.Compose([\n",
    "        A.Affine(scale=(0.95, 1.05), p=0.5),\n",
    "        A.OneOf([A.Affine(rotate=(-20, 20), p=0.5), A.Affine(shear=(-5, 5), p=0.5)], p=0.5),\n",
    "        A.Affine(translate_percent=(-0.05, 0.05), p=0.5),\n",
    "        A.Resize(224, 224),\n",
    "        A.Normalize([0.506, 0.506, 0.506], [0.287, 0.287, 0.287]),\n",
    "        ToTensorV2()\n",
    "    ]),\n",
    "    'val': A.Compose([\n",
    "        A.Resize(224, 224),\n",
    "        A.Normalize([0.506, 0.506, 0.506], [0.287, 0.287, 0.287]),\n",
    "        ToTensorV2()\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T07:09:18.290425Z",
     "iopub.status.busy": "2024-12-12T07:09:18.289696Z",
     "iopub.status.idle": "2024-12-12T07:09:18.720979Z",
     "shell.execute_reply": "2024-12-12T07:09:18.720276Z",
     "shell.execute_reply.started": "2024-12-12T07:09:18.290398Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('/kaggle/input/chexpertsmallclean/u1_test.csv',index_col=0)\n",
    "train = pd.read_csv('/kaggle/input/chexpertsmallclean/u1_train.csv', index_col=0)\n",
    "val = pd.read_csv('/kaggle/input/chexpertsmallclean/u1_val.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T07:09:18.722371Z",
     "iopub.status.busy": "2024-12-12T07:09:18.722027Z",
     "iopub.status.idle": "2024-12-12T07:09:18.798117Z",
     "shell.execute_reply": "2024-12-12T07:09:18.797266Z",
     "shell.execute_reply.started": "2024-12-12T07:09:18.722335Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train.index =  train.index.str.replace('CheXpert-v1.0-small', 'chexpert')\n",
    "test.index = test.index.str.replace('CheXpert-v1.0-small', 'chexpert')\n",
    "val.index = val.index.str.replace('CheXpert-v1.0-small', 'chexpert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T07:09:18.800251Z",
     "iopub.status.busy": "2024-12-12T07:09:18.799996Z",
     "iopub.status.idle": "2024-12-12T07:09:18.992240Z",
     "shell.execute_reply": "2024-12-12T07:09:18.991051Z",
     "shell.execute_reply.started": "2024-12-12T07:09:18.800227Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/sampler.py:228: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  weights_tensor = torch.as_tensor(weights, dtype=torch.double)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_dataset = CheXpertDataset(\n",
    "    data=train,\n",
    "    root_dir='/kaggle/input/', \n",
    "    mode='train',\n",
    "    transforms = transform\n",
    "    )\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_sampler = get_weighted_batch_sampler(train, batch_size),\n",
    "    num_workers = 4,\n",
    "    pin_memory=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T07:09:18.994376Z",
     "iopub.status.busy": "2024-12-12T07:09:18.993915Z",
     "iopub.status.idle": "2024-12-12T07:09:19.265738Z",
     "shell.execute_reply": "2024-12-12T07:09:19.264837Z",
     "shell.execute_reply.started": "2024-12-12T07:09:18.994319Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "pretrained_densenet = models.densenet121(pretrained=True)\n",
    "\n",
    "for param in pretrained_densenet.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Define a new classifier with additional layers\n",
    "class CustomDenseNet(nn.Module):\n",
    "    def __init__(self, pretrained_model, num_classes):\n",
    "        super(CustomDenseNet, self).__init__()\n",
    "        \n",
    "        # Retain the feature extraction part of the pre-trained DenseNet\n",
    "        self.features = pretrained_model.features\n",
    "        \n",
    "        # Add custom convolutional layers after the DenseNet feature extractor\n",
    "        self.additional_conv = nn.Sequential(\n",
    "            nn.Conv2d(1024, 512, kernel_size=3, padding=1),  # Example additional convolutional layer\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Global average pooling (to reduce spatial dimensions before the classifier)\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        # Final fully connected layer (classifier), adjusted for multi-label classification\n",
    "        self.classifier = nn.Linear(256, num_classes)  # 128 is the output channels from the conv layers\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        # Pass through the DenseNet feature extractor\n",
    "        x = self.features(x)\n",
    "        \n",
    "        # Pass through the additional convolutional layers\n",
    "        x = self.additional_conv(x)\n",
    "        \n",
    "        # Apply global average pooling\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Flatten the tensor and pass it through the classifier\n",
    "        x = torch.flatten(x, 1)  # Flatten the output from the pooling layer\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Replace the DenseNet's classifier with the custom classifier\n",
    "num_classes = 14\n",
    "model = CustomDenseNet(pretrained_densenet, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T07:09:19.267335Z",
     "iopub.status.busy": "2024-12-12T07:09:19.266969Z",
     "iopub.status.idle": "2024-12-12T07:09:19.478642Z",
     "shell.execute_reply": "2024-12-12T07:09:19.477475Z",
     "shell.execute_reply.started": "2024-12-12T07:09:19.267296Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = models.densenet121(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.classifier = nn.Linear(in_features=model.classifier.in_features, out_features=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T07:09:19.480338Z",
     "iopub.status.busy": "2024-12-12T07:09:19.479979Z",
     "iopub.status.idle": "2024-12-12T07:09:19.486928Z",
     "shell.execute_reply": "2024-12-12T07:09:19.485801Z",
     "shell.execute_reply.started": "2024-12-12T07:09:19.480286Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, betas=(0.9,0.999), weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T07:09:38.668327Z",
     "iopub.status.busy": "2024-12-12T07:09:38.667533Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:  30%|██▉       | 1416/4781 [02:43<05:58,  9.40batch/s]"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\"):\n",
    "        \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "# Print loss after each epoch\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-12T07:09:37.476314Z",
     "iopub.status.idle": "2024-12-12T07:09:37.476615Z",
     "shell.execute_reply": "2024-12-12T07:09:37.476483Z",
     "shell.execute_reply.started": "2024-12-12T07:09:37.476469Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_dataset = CheXpertDataset(test, '/kaggle/input/', \n",
    "                                mode='val', transforms = transform)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = 32,\n",
    "    num_workers = 4,\n",
    "    pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-12T07:09:37.477796Z",
     "iopub.status.idle": "2024-12-12T07:09:37.478095Z",
     "shell.execute_reply": "2024-12-12T07:09:37.477975Z",
     "shell.execute_reply.started": "2024-12-12T07:09:37.477961Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "all_labels = []  # To store all the true labels\n",
    "all_preds = []  # To store all the predicted probabilities\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(test_loader, desc=\"Testing\", unit=\"batch\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Get the logits from the model\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Apply sigmoid to the outputs to get probabilities\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "\n",
    "        # Collect the true labels and predictions\n",
    "        all_labels.append(labels.cpu().numpy())  # Convert to numpy and store\n",
    "        all_preds.append(outputs.cpu().numpy())  # Convert to numpy and store\n",
    "\n",
    "# Convert the list of arrays into a single numpy array for true labels and predictions\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n",
    "all_preds = np.concatenate(all_preds, axis=0)\n",
    "\n",
    "# Compute AUROC for multi-label classification\n",
    "auroc_scores = []\n",
    "for i in range(all_labels.shape[1]):  # Loop through each label\n",
    "    auroc = roc_auc_score(all_labels[:, i], all_preds[:, i])  # Calculate AUROC for each label\n",
    "    auroc_scores.append(auroc)\n",
    "\n",
    "# Calculate the mean AUROC score across all labels\n",
    "mean_auroc = np.mean(auroc_scores)\n",
    "print(f'Mean AUROC: {mean_auroc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-12-12T07:09:37.479629Z",
     "iopub.status.idle": "2024-12-12T07:09:37.480072Z",
     "shell.execute_reply": "2024-12-12T07:09:37.479854Z",
     "shell.execute_reply.started": "2024-12-12T07:09:37.479832Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to calculate and plot AUROC for multi-label classification\n",
    "def plot_auroc(model, dataloader, num_classes, device):\n",
    "    model.eval()\n",
    "    \n",
    "    true_labels = []\n",
    "    predicted_probs = []\n",
    "    \n",
    "    # Collect true labels and predicted probabilities\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Get raw model output (logits)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Apply sigmoid to get probabilities for each label\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            \n",
    "            true_labels.append(labels.cpu().numpy())\n",
    "            predicted_probs.append(probs.cpu().numpy())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    true_labels = np.vstack(true_labels)\n",
    "    predicted_probs = np.vstack(predicted_probs)\n",
    "\n",
    "    # Calculate AUROC for each label\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    roc_auc = {}\n",
    "\n",
    "    # Iterate over each label and compute the ROC curve and AUROC\n",
    "    for i in range(num_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(true_labels[:, i], predicted_probs[:, i])\n",
    "        roc_auc[i] = roc_auc_score(true_labels[:, i], predicted_probs[:, i])\n",
    "\n",
    "    # Plot the ROC curve for each label\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i in range(num_classes):\n",
    "        plt.plot(fpr[i], tpr[i], label=f'Class {i+1} (AUROC = {roc_auc[i]:.2f})')\n",
    "    \n",
    "    # Plot the diagonal (random guess line)\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random guess (AUROC = 0.5)')\n",
    "    \n",
    "    # Add labels and legend\n",
    "    plt.title('Multi-label (ROC) Curve')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    \n",
    "    # Return mean AUROC\n",
    "    mean_auroc = np.mean(list(roc_auc.values()))\n",
    "    print(f'Mean AUROC across all classes: {mean_auroc:.2f}')\n",
    "    return mean_auroc\n",
    "\n",
    "#model.to(device)\n",
    "#plot_auroc(model, test_loader, num_classes=14, device='cuda')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1302315,
     "sourceId": 2169393,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6282282,
     "sourceId": 10171849,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
