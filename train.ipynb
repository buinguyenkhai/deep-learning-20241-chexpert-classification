{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-12T18:07:34.398654Z",
     "iopub.status.busy": "2024-12-12T18:07:34.398278Z",
     "iopub.status.idle": "2024-12-12T18:07:34.412293Z",
     "shell.execute_reply": "2024-12-12T18:07:34.411343Z",
     "shell.execute_reply.started": "2024-12-12T18:07:34.398621Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbuinguyenkhai24\u001b[0m (\u001b[33mbuinguyenkhai24-hust\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import wandb\n",
    "# 381b331eeb89239808cb03e0163f2196237c7186\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T18:07:34.414971Z",
     "iopub.status.busy": "2024-12-12T18:07:34.413997Z",
     "iopub.status.idle": "2024-12-12T18:07:34.430288Z",
     "shell.execute_reply": "2024-12-12T18:07:34.429487Z",
     "shell.execute_reply.started": "2024-12-12T18:07:34.414942Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CheXpertDataset(Dataset):\n",
    "    '''\n",
    "    Custom dataset for CheXpert. Returns a tuple of (PIL.Image, torch.Tensor (float32)).\n",
    "    Args:\n",
    "        data (pd.Dataframe): dataset with image path as indexes and columns as labels, all values are 0 (negative) or 1 (postivive)\n",
    "        root_dir (str): root directory of dataset folder\n",
    "        mode ('train', 'val'): mode for different augmentation\n",
    "        transforms (albumentations): augmentation techniques to use\n",
    "    '''\n",
    "    def __init__(self, data, root_dir, mode='train', transforms=None):\n",
    "        self.data = data.to_numpy()\n",
    "        self.labels = torch.tensor(data.values.astype(np.float32))\n",
    "        self.root_dir = root_dir\n",
    "        self.img_paths = [os.path.join(root_dir, img_path) for img_path in data.index]\n",
    "        self.transform = transforms.get(mode)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image=np.array(image))['image']\n",
    "\n",
    "        return (image, label)\n",
    "    \n",
    "def get_weighted_sampler(data):\n",
    "    '''\n",
    "    Custom Sampler for weighted sampling to deal with unbalanced labels. The class weights are the inverse of the count of positives of a label.\n",
    "        Args:\n",
    "            data (pd.Dataframe): dataset with image path as indexes and columns as labels, all values are 0 (negative) or 1 (postivive)\n",
    "            batch_size (int): number of indices to use at a time \n",
    "    '''\n",
    "    class_weights = (1/data.sum()).values\n",
    "    weights = data.dot(class_weights)\n",
    "    weighted_sampler = WeightedRandomSampler(torch.tensor(weights.values, dtype=torch.float), len(weights), replacement=True)\n",
    "    return weighted_sampler\n",
    "'''\n",
    "Augmentations:\n",
    "    - Scale 5% with p = 50%\n",
    "    - Rotate 20Â° OR shear 5 pixels with p = 50%\n",
    "    - Translate 5% with p = 50%\n",
    "    - Resize to 224x224\n",
    "    - Normalize with mean = 0.506 and std = 0.287, more details in data_preprocessing.ipynb\n",
    "    - Convert to torch.Tensor\n",
    "'''\n",
    "transform = {\n",
    "    'train': A.Compose([\n",
    "        A.Affine(scale=(0.95, 1.05), p=0.5),\n",
    "        A.OneOf([A.Affine(rotate=(-20, 20), p=0.5), A.Affine(shear=(-5, 5), p=0.5)], p=0.5),\n",
    "        A.Affine(translate_percent=(-0.05, 0.05), p=0.5),\n",
    "        A.Resize(224, 224),\n",
    "        A.Normalize([0.506, 0.506, 0.506], [0.287, 0.287, 0.287]),\n",
    "        ToTensorV2()\n",
    "    ]),\n",
    "    'val': A.Compose([\n",
    "        A.Resize(224, 224),\n",
    "        A.Normalize([0.506, 0.506, 0.506], [0.287, 0.287, 0.287]),\n",
    "        ToTensorV2()\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T18:07:34.431624Z",
     "iopub.status.busy": "2024-12-12T18:07:34.431323Z",
     "iopub.status.idle": "2024-12-12T18:07:34.918922Z",
     "shell.execute_reply": "2024-12-12T18:07:34.918156Z",
     "shell.execute_reply.started": "2024-12-12T18:07:34.431596Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('/kaggle/input/chexpertclean/u1_test.csv',index_col=0)\n",
    "train = pd.read_csv('/kaggle/input/chexpertclean/u1_train.csv', index_col=0)\n",
    "val = pd.read_csv('/kaggle/input/chexpertclean/u1_val.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T18:07:34.921155Z",
     "iopub.status.busy": "2024-12-12T18:07:34.920857Z",
     "iopub.status.idle": "2024-12-12T18:07:34.998364Z",
     "shell.execute_reply": "2024-12-12T18:07:34.997672Z",
     "shell.execute_reply.started": "2024-12-12T18:07:34.921126Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train.index =  train.index.str.replace('CheXpert-v1.0-small', 'chexpert')\n",
    "test.index = test.index.str.replace('CheXpert-v1.0-small', 'chexpert')\n",
    "val.index = val.index.str.replace('CheXpert-v1.0-small', 'chexpert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm no data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T18:07:34.999571Z",
     "iopub.status.busy": "2024-12-12T18:07:34.999311Z",
     "iopub.status.idle": "2024-12-12T18:07:35.468650Z",
     "shell.execute_reply": "2024-12-12T18:07:35.467732Z",
     "shell.execute_reply.started": "2024-12-12T18:07:34.999521Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(np.intersect1d(train.index.to_numpy(), test.index.to_numpy()))\n",
    "print(np.intersect1d(val.index.to_numpy(), test.index.to_numpy()))\n",
    "print(np.intersect1d(val.index.to_numpy(), train.index.to_numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration for Bayes Hyperparameter Tuning using Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T18:07:35.470748Z",
     "iopub.status.busy": "2024-12-12T18:07:35.470058Z",
     "iopub.status.idle": "2024-12-12T18:07:35.821246Z",
     "shell.execute_reply": "2024-12-12T18:07:35.820336Z",
     "shell.execute_reply.started": "2024-12-12T18:07:35.470704Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: o9oj3pgz\n",
      "Sweep URL: https://wandb.ai/buinguyenkhai24-hust/deep_learning/sweeps/o9oj3pgz\n"
     ]
    }
   ],
   "source": [
    "sweep_config = {\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\n",
    "        \"name\": \"val_mAUC\",\n",
    "        \"goal\": \"maximize\"\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"learning_rate\": {\n",
    "            \"values\": [1e-3, 1e-4, 1e-5]\n",
    "        },\n",
    "        \"weight_decay\": {\n",
    "            \"values\": [1e-3, 1e-4, 1e-5]\n",
    "        },\n",
    "        \"patience\": {\n",
    "            \"values\": [0, 1, 5, 10]\n",
    "        },\n",
    "        \"drop_rate\": {\n",
    "            \"values\": [0, 0.1, 0.25, 0.5]\n",
    "        },\n",
    "        \"val_patience\": {\n",
    "            \"values\": [5, 10]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"deep_learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T18:07:35.822844Z",
     "iopub.status.busy": "2024-12-12T18:07:35.822421Z",
     "iopub.status.idle": "2024-12-12T18:07:35.826968Z",
     "shell.execute_reply": "2024-12-12T18:07:35.826088Z",
     "shell.execute_reply.started": "2024-12-12T18:07:35.822800Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#model = models.densenet121(pretrained=True)\n",
    "#for param in model.parameters():\n",
    "#    param.requires_grad = False\n",
    "#model.classifier = nn.Linear(in_features=model.classifier.in_features, out_features=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T18:07:35.828729Z",
     "iopub.status.busy": "2024-12-12T18:07:35.828310Z",
     "iopub.status.idle": "2024-12-12T18:07:36.083133Z",
     "shell.execute_reply": "2024-12-12T18:07:36.081977Z",
     "shell.execute_reply.started": "2024-12-12T18:07:35.828690Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataset = CheXpertDataset(\n",
    "    data=train,\n",
    "    root_dir='/kaggle/input/', \n",
    "    mode='train',\n",
    "    transforms = transform\n",
    "    )\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    sampler = get_weighted_sampler(train),\n",
    "    num_workers = 4,\n",
    "    pin_memory=True\n",
    "    )\n",
    "\n",
    "val_dataset = CheXpertDataset(\n",
    "    val, '/kaggle/input/',\n",
    "    mode='val',\n",
    "    transforms = transform)\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size = batch_size,\n",
    "    num_workers = 4,\n",
    "    pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T18:07:36.085081Z",
     "iopub.status.busy": "2024-12-12T18:07:36.084595Z",
     "iopub.status.idle": "2024-12-12T18:07:36.221847Z",
     "shell.execute_reply": "2024-12-12T18:07:36.221046Z",
     "shell.execute_reply.started": "2024-12-12T18:07:36.085027Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "        \n",
    "        model = models.densenet121(num_classes=14, drop_rate=config.drop_rate).to(device)\n",
    "        loss_function = nn.BCEWithLogitsLoss()\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=config.patience)\n",
    "\n",
    "        best_val_mAUC = 0\n",
    "        epochs_without_improvement = 0\n",
    "        max_epochs = 100\n",
    "        val_patience = config.val_patience\n",
    "        for epoch in range(max_epochs):\n",
    "            \n",
    "            model.train()\n",
    "            epoch_loss = 0.0\n",
    "            for inputs, labels in tqdm((train_loader), desc=f\"Epoch {epoch+1}/{max_epochs}\", unit=\"batch\"):\n",
    "                # Compute prediction and loss\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_function(outputs, labels)\n",
    "        \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "                # Accumulate loss\n",
    "                epoch_loss += loss.item()\n",
    "        \n",
    "            # Compute and print average loss for the epoch\n",
    "            avg_loss = epoch_loss / len(train_loader)\n",
    "            scheduler.step(avg_loss)\n",
    "            print(f\"Epoch {epoch+1}/{max_epochs}, Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "            model.eval()\n",
    "            all_labels = []\n",
    "            all_preds = []\n",
    "        \n",
    "            with torch.no_grad():\n",
    "                for X, y in tqdm(val_loader, desc=\"Testing\", unit=\"batch\"):\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "                    # Get the logits from the model\n",
    "                    outputs = model(inputs)\n",
    "            \n",
    "                    # Apply sigmoid to the outputs to get probabilities\n",
    "                    outputs = torch.sigmoid(outputs)\n",
    "            \n",
    "                    # Collect the true labels and predictions\n",
    "                    all_labels.append(labels.cpu().numpy())  # Convert to numpy and store\n",
    "                    all_preds.append(outputs.cpu().numpy())  # Convert to numpy and store\n",
    "            \n",
    "            # Convert the list of arrays into a single numpy array for true labels and predictions\n",
    "            all_labels = np.concatenate(all_labels, axis=0)\n",
    "            all_preds = np.concatenate(all_preds, axis=0)\n",
    "            \n",
    "            # Compute AUROC for multi-label classification\n",
    "            auroc_scores = []\n",
    "            for i in range(all_labels.shape[1]):  # Loop through each label\n",
    "                try:\n",
    "                    auroc = roc_auc_score(all_labels[:, i], all_preds[:, i])\n",
    "                    auroc_scores.append(auroc)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "        \n",
    "            val_mAUC = np.mean(auroc_scores)\n",
    "            print(f'Mean AUROC: {val_mAUC:.4f}')\n",
    "        \n",
    "            wandb.log({\"epoch\": epoch, \"train_loss\": avg_loss, \"val_mAUC\": val_mAUC})\n",
    "            \n",
    "            if val_mAUC > best_val_mAUC:\n",
    "                best_val_mAUC = val_mAUC\n",
    "                torch.save(model.state_dict(), \"DenseNetScratch-U1.pth\")\n",
    "                epochs_without_improvement = 0\n",
    "            else:\n",
    "                epochs_without_improvement += 1\n",
    "                \n",
    "            # Early stopping\n",
    "            if epochs_without_improvement >= val_patience:\n",
    "                print(\"Early stopping triggered!\")\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T18:07:36.224024Z",
     "iopub.status.busy": "2024-12-12T18:07:36.223708Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n9pahrq1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpatience: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tval_patience: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241212_180738-n9pahrq1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/buinguyenkhai24-hust/deep_learning/runs/n9pahrq1' target=\"_blank\">charmed-sweep-1</a></strong> to <a href='https://wandb.ai/buinguyenkhai24-hust/deep_learning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/buinguyenkhai24-hust/deep_learning/sweeps/o9oj3pgz' target=\"_blank\">https://wandb.ai/buinguyenkhai24-hust/deep_learning/sweeps/o9oj3pgz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/buinguyenkhai24-hust/deep_learning' target=\"_blank\">https://wandb.ai/buinguyenkhai24-hust/deep_learning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/buinguyenkhai24-hust/deep_learning/sweeps/o9oj3pgz' target=\"_blank\">https://wandb.ai/buinguyenkhai24-hust/deep_learning/sweeps/o9oj3pgz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/buinguyenkhai24-hust/deep_learning/runs/n9pahrq1' target=\"_blank\">https://wandb.ai/buinguyenkhai24-hust/deep_learning/runs/n9pahrq1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:   4%|â         | 171/4797 [00:34<13:47,  5.59batch/s]"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train, count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to calculate and plot AUROC for multi-label classification\n",
    "def plot_auroc(model, dataloader, num_classes, device):\n",
    "    model.eval()\n",
    "    \n",
    "    true_labels = []\n",
    "    predicted_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Get raw model output (logits)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Apply sigmoid to get probabilities for each label\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            \n",
    "            true_labels.append(labels.cpu().numpy())\n",
    "            predicted_probs.append(probs.cpu().numpy())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    true_labels = np.vstack(true_labels)\n",
    "    predicted_probs = np.vstack(predicted_probs)\n",
    "\n",
    "    # Calculate AUROC for each label\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    roc_auc = {}\n",
    "\n",
    "    # Iterate over each label and compute the ROC curve and AUROC\n",
    "    for i in range(num_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(true_labels[:, i], predicted_probs[:, i])\n",
    "        roc_auc[i] = roc_auc_score(true_labels[:, i], predicted_probs[:, i])\n",
    "\n",
    "    # Plot the ROC curve for each label\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i in range(num_classes):\n",
    "        plt.plot(fpr[i], tpr[i], label=f'Class {i+1} (AUROC = {roc_auc[i]:.2f})')\n",
    "    \n",
    "    # Plot the diagonal (random guess line)\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random guess (AUROC = 0.5)')\n",
    "    \n",
    "    # Add labels and legend\n",
    "    plt.title('Multi-label (ROC) Curve')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    \n",
    "    # Return mean AUROC\n",
    "    mean_auroc = np.mean(list(roc_auc.values()))\n",
    "    print(f'Mean AUROC across all classes: {mean_auroc:.2f}')\n",
    "    return mean_auroc\n",
    "\n",
    "#model.to(device)\n",
    "#plot_auroc(model, val_loader, num_classes=14, device='cuda')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1302315,
     "sourceId": 2169393,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6290422,
     "sourceId": 10182897,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
